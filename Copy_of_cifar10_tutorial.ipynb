{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of cifar10_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauratomaz/GitHub/blob/master/Copy_of_cifar10_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHDURHTaOuPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxQrGMnBOuPt",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Training a Classifier\n",
        "=====================\n",
        "\n",
        "What about data?\n",
        "----------------\n",
        "\n",
        "Generally, when you have to deal with image, text, audio or video data,\n",
        "you can use standard python packages that load data into a numpy array.\n",
        "Then you can convert this array into a ``torch.*Tensor``.\n",
        "\n",
        "-  For images, packages such as Pillow, OpenCV are useful\n",
        "-  For audio, packages such as scipy and librosa\n",
        "\n",
        "Specifically for vision, there is a package called\n",
        "``torchvision``, that has data loaders for common datasets such as\n",
        "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
        "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
        "\n",
        "For this tutorial, we will use the CIFAR10 dataset.\n",
        "The CIFAR-10 data set is composed of 60,000 32x32 colour images, 6,000 images per class, so 10 categories in total. The training set is made up of 50,000 images, while the remaining 10,000 make up the testing set. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
        "\n",
        "![cifar10](https://i2.wp.com/appliedmachinelearning.blog/wp-content/uploads/2018/03/cifar2.jpg?resize=427%2C325&ssl=1)\n",
        "\n",
        "``Cifar10``\n",
        "\n",
        "\n",
        "Training an image classifier\n",
        "----------------------------\n",
        "\n",
        "We will do the following steps in order:\n",
        "\n",
        "1. Load and normalizing the CIFAR10 training and test datasets using\n",
        "   ``torchvision``\n",
        "2. Define a Convolution Neural Network\n",
        "3. Define a loss function\n",
        "4. Train the network on the training data\n",
        "5. Test the network on the test data\n",
        "\n",
        "----\n",
        "1. Loading and normalizing CIFAR10\n",
        "\n",
        "\n",
        "Using ``torchvision``, it’s extremely easy to load CIFAR10.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8kwx28ROuPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQFUudEDOuQA",
        "colab_type": "text"
      },
      "source": [
        "This is the two-step process used to prepare the data for use with the convolutional neural network.\n",
        "\n",
        "First step is to convert Python Image Library (PIL) format to PyTorch tensors.\n",
        "\n",
        "Second step is used to normalize the data by specifying a mean and standard deviation for each of the three channels. This will convert the data from [0,1] to [-1,1]\n",
        "\n",
        "Normalization of data should help speed up conversion and reduce the chance of vanishing gradients with certain activation functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq4ewig3OuQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAkIIQPVOuQQ",
        "colab_type": "text"
      },
      "source": [
        "Let us show some of the training images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "avZB645j3dPB",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVmGKOXtOuQh",
        "colab_type": "text"
      },
      "source": [
        "2. Define a Convolution Neural Network\n",
        "\n",
        " Here, we define the neural network to take 3-channel images. Let's take a look step by step how the neural network processes the input.\n",
        "\n",
        "\n",
        "1. Input Image: The images are 3x32x32, i.e., 3 channels (red, green, blue) each of size 32x32 pixels.\n",
        "2. First Convolutional Layer: The first convolutional layer expects 3 input channels and will convolve 6 filters each of size 3x5x5. Since padding is set to 0 and stride is set to 1, the output size is 6x28x28, because (32 − 5) + 1 = 28. This layer therefore has ((5 × 5 × 3) + 1) × 6 = 456 parameters.\n",
        "3. First Max-Pooling Layer: The first down-sampling layer uses max pooling with a 2x2 kernel and stride set to 2. This effectively drops the size from 6x28x28 to 6x14x14.\n",
        "4. Second Convolutional Layer: The second convolutional layers expects 6 input channels and will convolve 16 filters each of size 6x5x5. Since padding is set to 0 and stride is set to 1, the output size is 16x10x10, because (14 − 5) + 1 = 10. This layer therefore has ((5 × 5 × 6) + 1) × 16 = 2416 parameters.\n",
        "5. First Fully-Connected Layer: The output from the final max pooling layer needs to be flattened so that we can connect it to a fully connected layer. This is achieved using the ``torch.Tensor.view`` method. By specifying ``-1`` the method will automatically infer the number of rows required. This is done to handle the mini-batch size of data. The fully-connected layer uses ReLU for activation and has 120 nodes, thus in total it needs ((16 × 5 × 5) + 1) × 120 = 48120 parameters.\n",
        "6. Second Fully-Connected Layer: The output from the first fully-connected layer is connected to another fully connected layer with 84 nodes, using ReLU as an activation function. This layer thus needs (120 + 1) × 84 = 10164 parameters.\n",
        "7. Output Layer: The last fully-connected layer uses softmax and is made up of ten nodes, one for each category in CIFAR-10. This layer requires (84 + 1) × 10 = 850 parameters.\n",
        "\n",
        "Total Network Parameters\n",
        "This convolutional neural network has a total of 456 + 2416 + 48120 + 10164 + 850 = 62006 parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0rQCV8kOuQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAG56339OuQw",
        "colab_type": "text"
      },
      "source": [
        "3. Define a Loss function and optimizer\n",
        " \n",
        " Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyVanjduOuQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGdIGVjHOuRB",
        "colab_type": "text"
      },
      "source": [
        "4. Train the network\n",
        "\n",
        " Here we loop over our data iterator, and feed the inputs to the\n",
        "network and optimize. \n",
        "\n",
        " We will now train the network using the trainloader data, by going over all the training data in batches of 4 images, and repeating the whole process 2 times, i.e., 2 epochs. Every 2000 batches we report on training progress by printing the current epoch and batch number along with the running loss value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veCUuWR3OuRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-41t9v-kOuRU",
        "colab_type": "text"
      },
      "source": [
        "5. Test the network on the test data\n",
        "\n",
        " We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        " We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        " First, let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLXlIbt8OuRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-ZPKZqCOuRj",
        "colab_type": "text"
      },
      "source": [
        "Now, let us see what the neural network thinks these examples above are:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5P_AQ1IOuRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = net(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKE5WkMyOuRw",
        "colab_type": "text"
      },
      "source": [
        "The outputs are accuracy for the 10 classes.\n",
        "Higher the accuracy for a class, the more the network\n",
        "thinks that the image is of the particular class.\n",
        "So, let's get the index of the highest accuracy:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuWZSLonOuR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukWlDo3kOuSD",
        "colab_type": "text"
      },
      "source": [
        "Now, let us look at how the network performs on the whole dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcVwvnRXOuSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wfkwFuLOuSU",
        "colab_type": "text"
      },
      "source": [
        "Our results look better than chance, which is 10% accuracy (randomly picking\n",
        "a class out of 10 classes).\n",
        "Seems like the network learnt something.\n",
        "\n",
        "What are the classes that performed well, and the classes that did\n",
        "not perform well:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYWSzIcnOuSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "cf_matrix = np.zeros([10,10], int)\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        #print(labels)\n",
        "        outputs = net(images)\n",
        "        #print(outputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        #print(predicted)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        #print(c)\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "        for i, l in enumerate(labels):\n",
        "            cf_matrix[l.item(), predicted[i].item()] += 1 \n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFzMb85cYinK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, title=None, cmap=plt.cm.Blues):\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    \n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "    \n",
        "    # Rotate the tick labels and set their alignment\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
        "    \n",
        "    # Loop over data dimensions and create text annotations\n",
        "    thresh = cm.max() / .2\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], 'd'),\n",
        "                    ha='center', va='center', \n",
        "                    color='white' if cm[i, j] > thresh else 'black')\n",
        "    fig.tight_layout()\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoEg_9LUa1kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "ax.matshow(cf_matrix, aspect='auto', cmap=plt.get_cmap('Blues'))\n",
        "plt.ylabel('Actual Category')\n",
        "plt.yticks(range(10), classes)\n",
        "plt.xlabel('Predicted Category')\n",
        "plt.xticks(range(10), classes)\n",
        "for i in range(cf_matrix.shape[0]):\n",
        "  for j in range(cf_matrix.shape[1]):\n",
        "    ax.text(j, i, format(cf_matrix[i, j], 'd'),\n",
        "            ha='center', va='center', \n",
        "            color='black')\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5dLWDIvOuSl",
        "colab_type": "text"
      },
      "source": [
        "So what next?\n",
        "\n",
        "How do we run these neural networks on the GPU?\n",
        "\n",
        "Training on GPU\n",
        "----------------\n",
        "Just like how you transfer a Tensor on to the GPU, you transfer the neural\n",
        "net onto the GPU.\n",
        "\n",
        "First, let's check if our device has a GPU ready to run these neural networks. We define our device as the first visible cuda device if we have CUDA available:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKCu1nSoOuSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assume that we are on a CUDA machine, then this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}